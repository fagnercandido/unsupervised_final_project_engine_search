{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ed8fd0-96d6-4906-858f-1006b3a87e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/fagnercandido/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/fagnercandido/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import ssl\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import math\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from gensim.models import KeyedVectors\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe8beb4-361c-4555-af2a-eed87d1cbce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash.dependencies import Input, Output, State\n",
    "from dash import html\n",
    "from dash import dcc\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import Dash, html, dcc\n",
    "import flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4329004-9279-48de-95a8-694ea92d0a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eligible_files():\n",
    "    elegible_files = []\n",
    "    for file in os.listdir('reuters21578'):\n",
    "        if file.endswith('.sgm'):\n",
    "            elegible_files.append(file)\n",
    "    return elegible_files\n",
    "\n",
    "def get_documents():\n",
    "    documents = []\n",
    "    files = get_eligible_files()\n",
    "    for file in files:\n",
    "        content = ''\n",
    "        try:\n",
    "            content = open(f'reuters21578/{file}', 'r', encoding=\"utf-8\").read()\n",
    "        except UnicodeDecodeError as e:\n",
    "            lines = []\n",
    "            for line in open(f'reuters21578/{file}', 'rb').readlines():\n",
    "                line = line.decode('utf-8','ignore') #.encode(\"utf-8\")\n",
    "                lines.append(line)\n",
    "            content = '\\n'.join(lines)\n",
    "        soup_document = BeautifulSoup(content.lower(), 'html.parser')\n",
    "        for document in soup_document.findAll('reuters'):\n",
    "            documents.append(document)\n",
    "    return documents\n",
    "\n",
    "def get_documents_by_dictionary_article():\n",
    "    articles = {}\n",
    "    for article in get_documents():\n",
    "        new_id = article.get('newid')\n",
    "        date_article = find_element_by_name(article, 'date')\n",
    "        topics = find_element_by_name(article, 'topics')\n",
    "        places = find_element_by_name(article, 'places')\n",
    "        people = find_element_by_name(article, 'people')\n",
    "        title = find_element_by_name(article, 'title')\n",
    "        dateline = find_element_by_name(article, 'dateline')\n",
    "        body = find_element_by_name(article, 'body')\n",
    "        metadados_article = {}\n",
    "        for item in ['date_article', 'dateline', 'topics', 'places', 'people', 'title', 'body']:\n",
    "            metadados_article[item] = eval(item)\n",
    "        articles[new_id] = metadados_article\n",
    "    return articles\n",
    "\n",
    "def find_element_by_name(article, tag):\n",
    "    element = article.find_all(tag)\n",
    "    if element:\n",
    "        return next((x.text for x in element))\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def preprocess_tokenize_and_lemmatize_and_add_frequency_matrix():\n",
    "    articles = get_documents_by_dictionary_article()\n",
    "    for item, value in articles.items():\n",
    "        articles[item]['body_lemmatized'] = remove_stop_word_and_lemmatize(value['body'])\n",
    "        articles[item]['topics_lemmatized'] = remove_stop_word_and_lemmatize(value['topics'], True) \n",
    "        articles[item]['body_frequency'] = create_frequency_matrix(articles[item]['body_lemmatized'])\n",
    "        articles[item]['body_tfidf'] = create_tf_idf(value['body'])\n",
    "    return articles\n",
    "\n",
    "def add_pca(values):\n",
    "    pca = PCA(n_components=100)\n",
    "    pca.fit(np.array(list(values.items())))\n",
    "    return pca.fit_transform(np.array(list(values.items())))\n",
    "\n",
    "def show_pca(values):\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(np.array(values.values()))\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    plt.plot(pca.singular_values_)\n",
    "    PC = pca.fit_transform(np.array(values.values()))\n",
    "\n",
    "def create_tf_idf(value):\n",
    "    if value:\n",
    "        cv = CountVectorizer()\n",
    "        word_count_vector = cv.fit_transform(list(filter(None, value.split('\\n'))))\n",
    "        \n",
    "        tfidf_transformer = TfidfTransformer(smooth_idf = True, use_idf = True)\n",
    "        tfidf_transformer.fit(word_count_vector)\n",
    "        \n",
    "        count_vector = cv.transform(list(filter(None, value.split('\\n')))) \n",
    "        tf_idf_vector = tfidf_transformer.transform(count_vector)\n",
    "        \n",
    "        feature_names = cv.get_feature_names()\n",
    "        first_document_vector = tf_idf_vector[0]\n",
    "        dataframe = pd.DataFrame(first_document_vector.T.todense(), index = feature_names, columns=[\"tfidf\"])\n",
    "        dataframe = dataframe.sort_values(by = [\"tfidf\"], ascending=False)\n",
    "        \n",
    "        dataframe.dropna(inplace = True)\n",
    "        dataframe_to_dict = dataframe.to_dict()\n",
    "        return list(dataframe_to_dict.values())[0]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def remove_stop_word_and_lemmatize(value, is_topic = False):\n",
    "    result = []\n",
    "    if value:\n",
    "        for token in gensim.utils.simple_preprocess(value):\n",
    "            if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "                result.append(nltk.stem.WordNetLemmatizer().lemmatize(token, pos='v'))\n",
    "    return set(result) if is_topic else result\n",
    "\n",
    "def create_frequency_matrix(value):\n",
    "    frequency_table = {}\n",
    "    for word in value:\n",
    "        if word in frequency_table:\n",
    "            frequency_table[word] += 1\n",
    "        else:\n",
    "            frequency_table[word] = 1\n",
    "    return frequency_table\n",
    "\n",
    "def search(query_string, articles):\n",
    "    articles_selected = {}\n",
    "    query_string_lemmatized = remove_stop_word_and_lemmatize(query_string)\n",
    "    for token in query_string_lemmatized:\n",
    "        for key, value in articles.items():\n",
    "            list_of_values = list(value['body_frequency'].keys())\n",
    "            if token in list_of_values and list_of_values.index(token) > 0.0:\n",
    "                if key in articles_selected:\n",
    "                    articles_selected[key]['relative_weight']  = articles_selected[key]['relative_weight'] + list_of_values.index(token)\n",
    "                else:\n",
    "                    articles_selected[key] = {'article': value, 'relative_weight': list_of_values.index(token)}\n",
    "    prepare_visualization(sorted(articles_selected.items(), key=lambda x: x[1]['relative_weight'], reverse=True))\n",
    "\n",
    "    \n",
    "def search_with_dash(query, articles):\n",
    "    articles_selected = {}\n",
    "    query_string_lemmatized = remove_stop_word_and_lemmatize(query)\n",
    "    for token in query_string_lemmatized:\n",
    "        for key, value in articles.items():\n",
    "            list_of_values = list(value['body_frequency'].keys())\n",
    "            if token in list_of_values and list_of_values.index(token) > 0.0:\n",
    "                if key in articles_selected:\n",
    "                    articles_selected[key]['relative_weight']  = articles_selected[key]['relative_weight'] + list_of_values.index(token)\n",
    "                else:\n",
    "                    articles_selected[key] = {'article': value, 'relative_weight': list_of_values.index(token)}\n",
    "    return sorted(articles_selected.items(), key=lambda x: x[1]['relative_weight'], reverse=True)\n",
    "\n",
    "\n",
    "    \n",
    "def prepare_visualization(articles):\n",
    "    print(f'\\t\\tMy Favorite Engine')\n",
    "    print()\n",
    "    for item in articles:\n",
    "        value = item[1]\n",
    "        print(f'{value[\"article\"][\"title\"]} - {value[\"article\"][\"date_article\"]}')\n",
    "        print(f'{value[\"article\"][\"body\"][:50]}...')\n",
    "        print()\n",
    "        \n",
    "def added_pca_in_articles(articles):\n",
    "    pca = PCA(n_components=100)\n",
    "    \n",
    "    tfidf_m = prepare_to_tfidf(articles)\n",
    "    \n",
    "    pca.fit(tfidf_m)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    plt.plot(pca.singular_values_)\n",
    "    \n",
    "    #PC = pca.fit_transform(tfidf_m)\n",
    "    #plt.imshow(PC)\n",
    "    \n",
    "def prepare_to_tfidf(articles):\n",
    "    tfidf = []\n",
    "    for item in articles:\n",
    "        tfidf.append(articles[item]['body_tfidf'])\n",
    "    labels = unique_corpus_words(tfidf)\n",
    "    return tfidf_matrix_th(tfidf, labels)\n",
    "    \n",
    "def tfidf_matrix_th(TFIDFth, labels):\n",
    "    Mtfidf = np.zeros([len(TFIDFth), len(labels)])\n",
    "    count = 0\n",
    "    for docid in TFIDFth:\n",
    "        for word in docid:\n",
    "            Mtfidf[count, labels.index(word)] = docid[word]\n",
    "        count = count + 1\n",
    "    return Mtfidf\n",
    "\n",
    "def added_svd_in_articles(articles):\n",
    "    svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
    "    tfidf_m = prepare_to_tfidf(articles)\n",
    "    svd.fit(tfidf_m)\n",
    "    plt.plot(svd.singular_values_)\n",
    "    \n",
    "    SV = svd.fit_transform(tfidf_m)\n",
    "    \n",
    "    Q1 = svd.components_[:,0:10].transpose()\n",
    "    RLlsa=[]\n",
    "    for i in range(SV.shape[0]):\n",
    "        RLlsat = []\n",
    "        for j in range(Q1.shape[0]):\n",
    "            RLlsat.append(np.dot(SV[i,:],Q1[j])/(np.linalg.norm(SV[i,:])*np.linalg.norm(Q1[j])))\n",
    "        RLlsa.append(np.asarray(RLlsat).mean()) # I have used the mean but any other formula would be ok\n",
    "    \n",
    "    res_lsa = np.asarray(RLlsa)\n",
    "    print(res_lsa)\n",
    "    \n",
    "    rank_lsa = res_lsa.argsort()\n",
    "    ranked_lsa = rank_lsa[::-1][:10]+1 # reverse the sort to descend order\n",
    "    print(ranked_lsa)\n",
    "\n",
    "def unique_corpus_words(TFIDFth):\n",
    "    words=[]\n",
    "    for docid in TFIDFth:\n",
    "        for word in docid:\n",
    "            words.append(word)\n",
    "    return list(set(words))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2548bab0-bd06-43a6-a2c1-42edfa5eb753",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = preprocess_tokenize_and_lemmatize_and_add_frequency_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab68d301-95ca-47e8-8fd5-c41520f35d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_pca_in_articles(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "866763e3-e335-46f3-90a6-2a08c408ec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/gdzgsvwd67l_33fm_5xymqmm0000gn/T/ipykernel_29042/883564323.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  RLlsat.append(np.dot(SV[i,:],Q1[j])/(np.linalg.norm(SV[i,:])*np.linalg.norm(Q1[j])))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03757785 -0.0549296  -0.10176988 ...  0.03364004  0.0124883\n",
      "  0.03206155]\n",
      "[ 8002  7588  7530 14682  7542  7545 18970  7547  7549  7558]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeFElEQVR4nO3de3Sc9X3n8fd3bpoZSbbuQviC8IWr2xjwEhLCpZA05LIBtid7kt2kbJNdcjbJlrTJIWTTbkmb7snJya3p2bJLAq1zb5rQQEhDQ5wQQkIAcXMNBmyMDbaFJNuSJVmXuX33j3lkFCNZY0vy+Jnn8zpHZ2YezWi+vwP+zDPf5/c8P3N3REQkfGLVLkBERI6PAlxEJKQU4CIiIaUAFxEJKQW4iEhIJU7km7W1tXl3d/eJfEsRkdB79NFH97l7+5HbT2iAd3d309PTcyLfUkQk9Mxs10zb1UIREQkpBbiISEgpwEVEQkoBLiISUgpwEZGQqjjAzSxuZo+b2d3B4xYzu9fMtgW3zYtXpoiIHOlY9sBvALZOe3wTsMnd1wKbgsciInKCVBTgZrYceBvw1WmbrwY2Bvc3AtcsaGXT/PyZfv7uvu2L9edFREKp0j3wLwE3AqVp2zrdvRcguO1Y2NJe8avt+/jypm2USrp2uYjIlDkD3MzeDvS7+6PH8wZmdr2Z9ZhZz8DAwPH8CdZ2NjCRL7FnaPy4Xi8iUosq2QO/GHiHme0EvgNcYWbfAPrMrAsguO2f6cXufqu7b3D3De3trzqVvyJrOhoB2NY/clyvFxGpRXMGuLt/wt2Xu3s38C7gZ+7+HuAu4LrgadcBdy5WkWs6GgDY1je6WG8hIhI685kH/hngTWa2DXhT8HhRLM0k6VxSx3MKcBGRw47paoTufh9wX3B/P3Dlwpc0s7UdjWxXC0VE5LDQnIm5pqOBbf2juGsmiogIhCjA13Y2MJYrsvfgRLVLERE5KYQnwKdmovSpjSIiAqEK8PJMlO39OpApIgIhCvDm+hRtDSlNJRQRCYQmwGHqQKZaKCIiELIAX9vRqJkoIiKBcAV4ZwMjEwX6RyarXYqISNWFKsB1Sr2IyCtCFeBrdVErEZHDQhXgbQ0plmaSbNNUQhGRcAW4mbG2o4HtaqGIiIQrwKF8IFMtFBGREAZ419IMg2N5CsXS3E8WEalhoQvwTDIOwHi+WOVKRESqK3QBnk4pwEVEIIQBng32wCdyaqGISLSFLsAzwR74WL5Q5UpERKortAE+nlMLRUSibc4AN7O0mT1sZk+a2VNm9qlg+81mtsfMngh+3rr45U47iKkAF5GIq2RR40ngCncfNbMk8ICZ/Tj43Rfd/XOLV96raRaKiEjZnAHu5Wu3Tp36mAx+qnY916xmoYiIABX2wM0sbmZPAP3Ave7+UPCrD5vZZjO73cyaF6vI6dLBHviYWigiEnEVBbi7F919PbAcuNDM1gG3AKuB9UAv8PmZXmtm15tZj5n1DAwMzLvgqT3wCe2Bi0jEHdMsFHcfAu4DrnL3viDYS8BXgAtnec2t7r7B3Te0t7fPt95XphFqD1xEIq6SWSjtZtYU3M8AbwSeMbOuaU+7FtiyKBUeIZ3QLBQREahsFkoXsNHM4pQD/7vufreZfd3M1lM+oLkT+MCiVTlNLGakkzG1UEQk8iqZhbIZOG+G7e9dlIoqkEnG1UIRkcgL3ZmYUA5wTSMUkagLZ4CnFOAiIuENcLVQRCTiQhng2WRCAS4ikRfKAE+n4oyphSIiERfKAM8kY0xoD1xEIi6UAZ5NJXQQU0QiL5QBntY8cBGRcAZ4JhnXmZgiEnmhDPBsKs5YrkD5UuUiItEUygDPpOKUHHJFrUwvItEVzgAPFnWYyCnARSS6whngU9cEzxeqXImISPWEM8C1Mr2ISEgDXKvyiIiENMCTWhdTRCSUAT61sLHOxhSRKAtlgKeTaqGIiIQywKd64GqhiEiUVbIqfdrMHjazJ83sKTP7VLC9xczuNbNtwW3z4pdbdriFoj1wEYmwSvbAJ4Er3P01wHrgKjO7CLgJ2OTua4FNweMTIqMWiojI3AHuZaPBw2Tw48DVwMZg+0bgmsUocCZTPXAdxBSRKKuoB25mcTN7AugH7nX3h4BOd+8FCG47Fq3KI9QlYsRMLRQRibaKAtzdi+6+HlgOXGhm6yp9AzO73sx6zKxnYGDgOMt81d8kk9TK9CISbcc0C8Xdh4D7gKuAPjPrAghu+2d5za3uvsHdN7S3t8+v2mkyWpVHRCKuklko7WbWFNzPAG8EngHuAq4LnnYdcOci1TijTCqmFoqIRFqigud0ARvNLE458L/r7neb2YPAd83s/cCLwDsXsc5XySTjCnARibQ5A9zdNwPnzbB9P3DlYhRViUwqwZhaKCISYaE8ExMgk4wxoT1wEYmwEAe4ZqGISLSFNsCzqQRjOa3IIyLRFdoATyfjTOS1JqaIRFdoAzybUgtFRKIttAGeScXVQhGRSAttgE+1UEolr3YpIiJVEdoAn7om+ERBbRQRiabQBvjUNcF1NqaIRFV4A1wLG4tIxIU3wLUHLiIRF/4A1x64iERUaAN86iCm1sUUkagKbYCn1QMXkYgLbYBPtVB0RUIRiarQBrhaKCISdaENcB3EFJGoC2+ApzSNUESiLbQBntYeuIhEXCWr0q8ws5+b2VYze8rMbgi232xme8zsieDnrYtf7iuS8RjJuCnARSSyKlmVvgB81N0fM7NG4FEzuzf43Rfd/XOLV97RaWV6EYmySlal7wV6g/sjZrYVWLbYhVUik1KAi0h0HVMP3My6gfOAh4JNHzazzWZ2u5k1L3Rxc9HCxiISZRUHuJk1AN8HPuLuw8AtwGpgPeU99M/P8rrrzazHzHoGBgbmX/E0mVRC88BFJLIqCnAzS1IO72+6+x0A7t7n7kV3LwFfAS6c6bXufqu7b3D3De3t7QtVNwCZZIwJ7YGLSERVMgvFgNuAre7+hWnbu6Y97Vpgy8KXd3TZVELrYopIZFUyC+Vi4L3Av5nZE8G2/wm828zWAw7sBD6wCPUdVToZZ/+h3Il+WxGRk0Ils1AeAGyGX/3LwpdzbDKpuFooIhJZoT0TEyCbjKuFIiKRFeoA1zxwEYmy8Ae4WigiElHhDvBknHzRyRdL1S5FROSEC3WATy3qMDKhPriIRE+oA/x3lzcB8MD2fdUtRESkCkId4Bec1kxbQx33bOmtdikiIidcqAM8HjPefG4nP39mQLNRRCRyQh3gAG9Z18V4vsgvnlvYC2WJiJzsQh/gr13VQlM2qTaKiERO6AM8GY/xprM72bS1n8mC2igiEh2hD3CAt/zOKYxMFvj19v3VLkVE5ISpiQC/eE0bjXUJfqw2iohESE0EeF0izhVnd3Dv030UdFamiERETQQ4wBVndTA4lue5vtFqlyIickLUTICvbm8AYNf+Q1WuRETkxKiZAO9uqwfgBQW4iEREzQR4Q12CtoY6du0bq3YpIiInRM0EOEB3a1Z74CISGZWsSr/CzH5uZlvN7CkzuyHY3mJm95rZtuC2efHLPbrutnp27lOAi0g0VLIHXgA+6u5nAxcBHzKzc4CbgE3uvhbYFDyuqu7WLP0jk1onU0QiYc4Ad/ded38suD8CbAWWAVcDG4OnbQSuWaQaKzZ1IHOn+uAiEgHH1AM3s27gPOAhoNPde6Ec8kDHgld3jLpbywGuqYQiEgUVB7iZNQDfBz7i7sPH8LrrzazHzHoGBhb3kq+aSigiUVJRgJtZknJ4f9Pd7wg295lZV/D7LqB/pte6+63uvsHdN7S3ty9EzbPSVEIRiZJKZqEYcBuw1d2/MO1XdwHXBfevA+5c+PKOnaYSikhUVLIHfjHwXuAKM3si+Hkr8BngTWa2DXhT8LjqNJVQRKIiMdcT3P0BwGb59ZULW878dbdm+V4wlTCbmnN4IiKhVVNnYoKmEopIdNRegGsqoYhERO0FuKYSikhE1FyAayqhiERFzQU4aCqhiERDbQa4phKKSATUZoDrqoQiEgG1GeDBgcwdA9oLF5HaVZMB/prlTQD07DxQ3UJERBZRTQb4ipYsy5sz/Pr5/dUuRURk0dRkgANcvLqN3+zYT7Hk1S5FRGRR1GyAv35NK8MTBZ7ae7DapYiILIqaDfDXrW4FUBtFRGpWzQZ4R2OatR0N/Gr7vmqXIiKyKGo2wAFev7qVR3YeIFcoVbsUEZEFV9sBvqaNiXyJJ14aqnYpIiILrqYD/KLTW4kZaqOISE2q6QBfmk2ybtlSHtSBTBGpQTUd4FCejfL4S4O6LoqI1JxKVqW/3cz6zWzLtG03m9meIxY5PildvLqNfNH56db+apciIrKgKtkD/wfgqhm2f9Hd1wc//7KwZS2c169u5YzOBj7/k2eZLBSrXY6IyIKZM8Dd/X4gtFeFSsRjfPJt57Br/xhf+/WuapcjIrJg5tMD/7CZbQ5aLM0LVtEiuOyMdi47o50v/2wbBw7lql2OiMiCON4AvwVYDawHeoHPz/ZEM7vezHrMrGdgYOA4327+/uxtZzOWK/I3P32uajWIiCyk4wpwd+9z96K7l4CvABce5bm3uvsGd9/Q3t5+vHXO29rORt594Qq+8dCLfOM3uxjUnriIhNxxBbiZdU17eC2wZbbnnkz+5I1nsLajgT/7wRb+3V//lD/6+4e547HdjE5qiqGIhI+5H/162Wb2beByoA3oA/4ieLwecGAn8AF3753rzTZs2OA9PT3zqXfe3J2n9g7zwyf3cvfmXvYMjVOXiHHl2R188PI1rFu2tKr1iYgcycwedfcNr9o+V4AvpJMhwKcrlZzHXxrkrif28sPNvYxM5Pn4VWfxvotPJxazapcnIgLMHuA1fybm0cRixgWntfCpq9ex6U8v4/IzO/j0j7by/o2PaLaKiJz0Ih3g0zXXp7j1vRfwl1efy6+e389/+spvODier3ZZIiKzUoBPY2b84eu6ue26DWzvH+X6r/UwkdfZmyJyclKAz+CSte187p2v4aEXDvCn331CCyOLyEkpUe0CTlbXnLeMfaOTfPpHW+lufZYbrzqr2iWJiPwW7YEfxX+9ZBXvvGA5t96/g219I9UuR0TktyjA53DTW84im4pz8w+f4kROuRQRmYsCfA6tDXV89PfP5Ffb93PPlperXY6IyGEK8Ar859eu5KxTGvn0j7YyntOsFBE5OSjAK5CIx7j5HeeyZ2icW+7bXu1yREQABXjFLlrVytXrT+WWXzyvA5oiclJQgB+DP3/7OdTXJfj49zdrbriIVJ0C/Bi0NdTxv95+Do+9OMTXH9xZ7XJEJOIU4Mfo2vOWcekZ7Xz2X59l9+BYtcsRkQhTgB8jM+Ovr1kHwMf+6UmtdC8iVaMAPw4rWrL81dXr+M2OA/yPbz1OvliqdkkiEkEK8OP0Bxcs5+Z/fw4/ebqPj/3TkzqoKSInnC5mNQ//5eLTGcsX+ew9zzI0lueStW2s7Wzk7K5GOhrT1S5PRGqcAnyePnj5GgBuf+AFfvHcwOHtZ3Y2cukZbfzemR1ctKpVS7SJyIKL9JqYC+3AoRzb+kZ4/KUhfrltgEdeGCRXLNHdmuU9F53GOy9YwdJsstplikjIHPeixmZ2O/B2oN/d1wXbWoB/BLopr0r/H919cK4iaj3AjzSWK3Dv0318/cFd9OwaJJuK898vW81/u3QV6WS82uWJSEjMJ8AvBUaBr00L8M8CB9z9M2Z2E9Ds7h+fq4ioBfh0T+09yN9u2s49T73MsqYMH3vzGVywsoWupjTJuI4li8jsjjvAgxd3A3dPC/BngcvdvdfMuoD73P3Muf5OlAN8yoPP7+cv736arb3DAMRjxvLmDG8+9xT+4PzlnHlKY5UrFJGTzUIH+JC7N037/aC7N8/y2uuB6wFWrlx5wa5du45rALWkWHJ6dh5g1/4xXhoc4+m9w/ziuQEKJefcU5dw7qlL6FqaYVlzhvNWNLGmowEzHQQViarZAnzRZ6G4+63ArVDeA1/s9wuDeMx47apWXruq9fC2/aOT3PnEXn68pZf7nh1gYHSSqc/W9sY6Xr+6lWvWL+OyM9o1o0VEgOMP8D4z65rWQulfyKKiqLWhjve94XTe94bTAcgVSuweHOPhFw7w6+f388C2fdz5xF5WtdfzRxefziVr2mhvrKO+TjNBRaLqeP/13wVcB3wmuL1zwSoSAFKJGKvaG1jV3sC7LlxJrlDix1t6ue2BF/jzH2w5/LxsKs75K5v5D+cv46p1p5BNKdBFoqKSWSjfBi4H2oA+4C+AHwDfBVYCLwLvdPcDc72ZDmLOn7uzefdBtvePMjA6ycsHJ9j0TB8vHRgnm4pz5dmdXHZGO5eubaNjic4GFakF8zqIuVAU4IvD3enZNcgdj+3m3qf72Tc6CcDajgbOX9nMeSub+N3l5YOhqYSmLIqEjQI8IkolZ+vL5VktD79wgMdfHOLgeB6ARMxY3d7ABd3NXPe6bk1ZFAkJBXhEuTs79h3iqb3DPNM7zNbeYR7csZ+JfIlLz2jn+ktWcfGaVk1TFDmJKcDlsMFDOb750C42PriLgZFJLjy9hRvffCYbuluqXZqIzEABLq8yWSjyj4+8xJc3bWff6CRXntXBp69dR9fSTLVLE5FpZgtwHdGKsLpEnD98XTf333g5N151Jg/u2M9VX/olP9rcW+3SRKQCCnAhm0rwwcvX8KM/voTutno+9K3HuOE7j/OvT73Mywcnql2eiMxCLRT5Lfliib/dtI3/+4sd5IK1Pjsa6zjn1CWc3VX+WdmSZVlThraGlA5+ipwA6oHLMZnIF3m6d5jNLw2xec9Bnt47zPb+UQrT1v6sS8RY1lS+6NaypgydS9J0LU3TuTRNZ2OaziV1NGdTunaLyDxV7WJWEk7pZPkU/fNXvnKRyclCkR0Dh9g9OM7uwTH2DI6z9+A4ewbH2do7zL7R3Kv+TjJunNqUYWVLluXNWVa11bO2s4EzT2nklCVp7cGLzIMCXCpWl4gfbqPMJFco0T8yQd/wBH3Dk/QNT/Dy8AR7Bsd5aXCce7b0MjiWP/z8hroEp7fVs6q9npUtWToa62hvTNPemKIpm6I5m2JpJklce/AiM1KAy4JJJWIsby7vac/mwKEcz/WNsK1vhOcHDvH8wCg9Owe568m9zNbNa6xLsCSTpDGdoDGdoL4uwdJMkmVNGVYE/fjmbIqmbJIlmST1qTgJrXIkEaAAlxOqpT7FRatauWjatdABCsUSB8Zy9A9Psv9QjqGxHAcO5RgcyzMykWd4vMDwRJ5DkwUOHMqxvX+Uuzf3UizNnPqpeIxMKk5dIkYyHqMuEaOtsY5lTRm6lqZpzqaCD4Qkp7VmWdPRoHVKJXQU4HJSSMRjdDSm6Wis/AqKhWLpcItmaDzPwfE8w+N5xnJFDuUKjOeK5IslJgvln4HhSR7ZeYCXD0781sFYKC+ysaa9gY4ldcRjRiIWozmbZHlzlhUtGZrrU8TNiMeMpZmkAl9OCgpwCa1EfO6WzUxKJedQrsDwRIHh8Tw7Bg6xtXeYp3uHGRrLUSg5+aLzb3uG6BuenPFvxAy6W+s5d9lSLlnTxiVntOkMVjnhNI1Q5Cgm8kX2DI1zcDxPqeQUS86+0RzP9o3w7MvDPPbiEAMj5ZBf0ZKhraGOlmyK1oZU8OGSoWtp5nDvvjGdoEVTK+UYaRqhyHFIJ+Osbm941fa30QWUr/b4bN8Iv3xuH5v3HGRoLMfLwxNs3nPwcLAfKRXMn1/enGFNRwNndjaytrOBxnSSRNC+ScSNRNxIxmI0pBMkdVBWZqAAF5kHM+OsU5Zw1imvnlo5kS+yd2ic3oMTjE4WGMsVGB4vsHdonN2D47x4YIzvPPwS4/ninO/TlE3SWp+iMZ0km4qTTZX35pekyzN0lmaSLEknWZJJ0FCXJJOKU18XpymTor2xTlMxa5QCXGSRpJPxw+uazqZUcnYPjrN9YISxXJFi0H8vFEvkS06+UGJ4Is/+0fKsnOGJPOO5IoNj44xOvjI752id0ETMOGVpmo7GOpLxGKlEjEwyzoqWLKe1lqdhlmfsxEknY+UPgnSShnRCwX+SU4CLVFEsZqxszbKy9dgOxE535EHZkYny3v5YrsiBQzn2Do2zd2icfaM58sUShyYLvHxwgvu3DTCRL836d82gJZuiraGOtsYUmWScZDx2+EPg8PTMhhSnNr3S60/Ey22gukSMdDJOJhUnnYhpbv4imFeAm9lOYAQoAoWZmuwisrhiMaMxnaQxXT65qVLuTv/IJHuHxpnIl8gVS4zniuV59xMFDo7l2Hcox76Rqbn5efLFErlCiXzRg+mZRUYmChW9XyJmpJNx0sl40AaK0xRM1VzenKGjMU0qUf5wSAUfAvG4UZeI0VpfR1tD+QxdfSt4xULsgf+eu+9bgL8jIieQmdG5JE3nksrn3s9kqte/d2iCsVwhmIYZzL/PFxnPF5nIl5gIbsfzRcanfUN4YNs++kYmjtoGmi4VLx/kTcbLraCpE7bKHw7lbUszSZrry5djSCdjJGIxknFjSSZJa30drQ0pGuoSh79J1NeVW0hhoxaKiMxLJb3+uUwWigweypMrlMgVi+QKTqFUolByJvJF9o/m2D86yYHgW0C+UP7GMPWhMJYrMlkoMpEvMjA6yfaBUQYP5RmdrOzbAZSvzdOUTR4O9qkPikQsRjxmpJMxmjLlSzYszSZpyZa/ESzJJKhLlD8k6pIxlmaSNGXKHxyLfbG2+Qa4Az8xMwf+n7vfeuQTzOx64HqAlStXzvPtRKQW1SXinLJ04feAc0HQF4rl2+HxAvtHJ9k3mmMsVyAXtITKl2jIMziW49BkeXv5g8IZLxbLHyQHiwyNDzE4Vv6gmcvU5RzqU+VvCf/72t/htUdcQmK+5hvgF7v7XjPrAO41s2fc/f7pTwhC/VYon8gzz/cTEanYVE99SkcjrOk4/m8KU8ozgXIMjuUYHi+Uw75YYiJfnjU0NJZnaDzHeK7IWK7IeK5IYzo57/c90rwC3N33Brf9ZvbPwIXA/Ud/lYhIuGVScTKpDKcew0HjxXDc83rMrN7MGqfuA78PbFmowkRE5OjmswfeCfxz0KRPAN9y93sWpCoREZnTcQe4u+8AXrOAtYiIyDHQqVEiIiGlABcRCSkFuIhISCnARURCSgEuIhJSJ3RJNTMbAHYd58vbgCheNCuK447imCGa447imOHYx32au7cfufGEBvh8mFlPFC9XG8VxR3HMEM1xR3HMsHDjVgtFRCSkFOAiIiEVpgB/1aVqIyKK447imCGa447imGGBxh2aHriIiPy2MO2Bi4jINApwEZGQCkWAm9lVZvasmW03s5uqXc9iMLMVZvZzM9tqZk+Z2Q3B9hYzu9fMtgW3zdWudaGZWdzMHjezu4PHURhzk5l9z8yeCf6bv67Wx21mfxL8v73FzL5tZulaHLOZ3W5m/Wa2Zdq2WcdpZp8Isu1ZM3vzsbzXSR/gZhYH/g/wFuAc4N1mdk51q1oUBeCj7n42cBHwoWCcNwGb3H0tsCl4XGtuALZOexyFMf8NcI+7n0X5ssxbqeFxm9ky4I+BDe6+DogD76I2x/wPwFVHbJtxnMG/8XcB5wav+bsg8ypy0gc45WXatrv7DnfPAd8Brq5yTQvO3Xvd/bHg/gjlf9DLKI91Y/C0jcA1VSlwkZjZcuBtwFenba71MS8BLgVuA3D3nLsPUePjprz+QMbMEkAW2EsNjjlYF/jAEZtnG+fVwHfcfdLdXwC2U868ioQhwJcBL017vDvYVrPMrBs4D3gI6HT3XiiHPNBRxdIWw5eAG4Hpy3zX+phXAQPA3weto68GyxLW7LjdfQ/wOeBFoBc46O4/oYbHfITZxjmvfAtDgNsM22p27qOZNQDfBz7i7sPVrmcxmdnbgX53f7TatZxgCeB84BZ3Pw84RG20DmYV9HyvBk4HTgXqzew91a3qpDCvfAtDgO8GVkx7vJzyV6+aY2ZJyuH9TXe/I9jcZ2Zdwe+7gP5q1bcILgbeYWY7KbfGrjCzb1DbY4by/9O73f2h4PH3KAd6LY/7jcAL7j7g7nngDuD11PaYp5ttnPPKtzAE+CPAWjM73cxSlBv+d1W5pgVn5dWhbwO2uvsXpv3qLuC64P51wJ0nurbF4u6fcPfl7t5N+b/rz9z9PdTwmAHc/WXgJTM7M9h0JfA0tT3uF4GLzCwb/L9+JeXjPLU85ulmG+ddwLvMrM7MTgfWAg9X/Ffd/aT/Ad4KPAc8D3yy2vUs0hjfQPmr02bgieDnrUAr5aPW24LblmrXukjjvxy4O7hf82MG1gM9wX/vHwDNtT5u4FPAM8AW4OtAXS2OGfg25T5/nvIe9vuPNk7gk0G2PQu85VjeS6fSi4iEVBhaKCIiMgMFuIhISCnARURCSgEuIhJSCnARkZBSgIuIhJQCXEQkpP4/u3bZ8RUz56YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "added_svd_in_articles(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0619736c-c45e-478c-b166-b79486b88804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8782bfd1-7b16-4876-bade-48eb50af7cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987da7b1-3ecc-47ca-8558-5b1af66a721f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faed13f-c3c5-473d-b57e-136f0af2a219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc725430-2ef2-4f83-bff0-9c55d668120c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a009f2e-8835-4785-a273-059e6f7c7463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216998e0-279c-416c-978f-2b6fdb3c492f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f8db73-bcf1-477b-b661-f67da72c13bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84f236c9-0f67-4864-80a0-e1fbe977b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15e4e85e-ecc7-42a3-a761-5016b8bd010f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"app\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [26/May/2022 18:02:35] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 18:02:35] \"GET /_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 18:02:35] \"GET /_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 18:02:36] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 18:02:41] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 18:02:51] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 18:42:44] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [26/May/2022 18:48:36] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "server = flask.Flask('app')\n",
    "\n",
    "app = dash.Dash('app', server = server)\n",
    "app.css.config.serve_locally = True\n",
    "app.scripts.config.serve_locally = True\n",
    "\n",
    "app.layout = html.Main([\n",
    "     html.Link(\n",
    "        rel='stylesheet',\n",
    "        href='/static/index.css'\n",
    "    ),\n",
    "    html.Center([\n",
    "        html.Img(src=\"/static/foogle.png\", width=\"20%\", height=\"5%\", id=\"googleimg\"),\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.Span([\n",
    "                    dcc.Input(name=\"search\", id='input-on-submit', type=\"text\", placeholder=\"O que gostava de saber?\"),\n",
    "                ], id=\"inputspan\"),\n",
    "            ], id=\"maindiv\")\n",
    "        ]),\n",
    "        html.Section([\n",
    "            html.Div([\n",
    "                html.Button('Pesquisa Foogle', id='search-value', n_clicks=0),\n",
    "            ]),\n",
    "            html.Div([\n",
    "                html.Button('Estou com sorte', id='lucky-value', n_clicks=0),\n",
    "            ]),\n",
    "        ]),\n",
    "        html.Br(),\n",
    "        html.Br(),\n",
    "        html.Br(),\n",
    "        html.Br(),\n",
    "        html.Br(),\n",
    "        html.Div([\n",
    "            \n",
    "        ], id='container-button-basic'),\n",
    "    ]),   \n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('container-button-basic', 'children'),\n",
    "    Input('search-value', 'n_clicks'),\n",
    "    State('input-on-submit', 'value')\n",
    ")\n",
    "def update_output(n_clicks, value):\n",
    "    \n",
    "    articles_result = search_with_dash(value, articles)\n",
    "    #output = ''\n",
    "    result = []\n",
    "    for key, value in articles_result:\n",
    "        #value = item[1]\n",
    "        #output = output + f'{value[\"article\"][\"title\"]} - {value[\"article\"][\"date_article\"]}  {value[\"article\"][\"body\"][:50]}...'\n",
    "        result.append(html.Div([\n",
    "            html.P(f'{value[\"article\"][\"title\"]} - {value[\"article\"][\"date_article\"]}'),\n",
    "            html.P(f'{value[\"article\"][\"body\"][:50]}'),\n",
    "            html.Br()\n",
    "        ]))\n",
    "    return result\n",
    "\n",
    "@app.server.route('/static/<path:path>')\n",
    "def static_file(path):\n",
    "    static_folder = os.path.join(os.getcwd(), 'static')\n",
    "    return send_from_directory(static_folder, path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43fd8ba-ba4e-4209-a451-ca57973df0b6",
   "metadata": {},
   "source": [
    "# Usando Spacy/Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adc6b891-ca71-4c06-b6b4-f9c4ae468515",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner', 'tagger', 'textcat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f6d5013-6afe-46b1-9490-f50ddb501b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizar_com_spacy(texto):\n",
    "    doc = nlp(texto)\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop and token.is_alpha:\n",
    "            tokens.append(token.text.lower())\n",
    "    return tokens\n",
    "\n",
    "def juntar_vetores_por_soma(palavras, modelo):\n",
    "    vetor_final = np.zeros((1,600))\n",
    "    for palavra in palavras:\n",
    "        try:\n",
    "            vetor_final += modelo.get_vector(palavra)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return vetor_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e30231d6-f315-405f-a785-95c98cab981e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fagnercandido/opt/anaconda3/lib/python3.9/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/fagnercandido/opt/anaconda3/lib/python3.9/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/fagnercandido/opt/anaconda3/lib/python3.9/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/fagnercandido/opt/anaconda3/lib/python3.9/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/fagnercandido/opt/anaconda3/lib/python3.9/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/fagnercandido/opt/anaconda3/lib/python3.9/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/fagnercandido/opt/anaconda3/lib/python3.9/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/fagnercandido/opt/anaconda3/lib/python3.9/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artigos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[inco, ltd, said, expect, earlier, reported, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mason, benson, president, chief, operating, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[discovery, complicate, search, aids, vaccine,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[doctors, centers, disease, control, atlanta, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[economic, data, week, key, determining, inter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             artigos\n",
       "0  [inco, ltd, said, expect, earlier, reported, r...\n",
       "1  [mason, benson, president, chief, operating, o...\n",
       "2  [discovery, complicate, search, aids, vaccine,...\n",
       "3  [doctors, centers, disease, control, atlanta, ...\n",
       "4  [economic, data, week, key, determining, inter..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_para_tratamento = (value['body'].lower() for item, value in articles.items())\n",
    "articles_tratados = [tokenizar_com_spacy(doc) for doc in nlp.pipe(articles_para_tratamento, batch_size=1000, n_process=-1)]\n",
    "dataframe_artigos_tratados = pd.DataFrame({\"artigos\": articles_tratados})\n",
    "dataframe_artigos_tratados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de37d561-b44d-425c-a0fd-e22cca7eb00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38028049, 43562460)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_de_lista_de_tokens = [artigo for artigo in dataframe_artigos_tratados.artigos]\n",
    "\n",
    "modelo_skipgram = Word2Vec(sg = 1,\n",
    "                      window = 5,\n",
    "                      min_count = 5,\n",
    "                      alpha = 0.03,\n",
    "                      min_alpha = 0.007)\n",
    "modelo_skipgram.build_vocab(lista_de_lista_de_tokens, progress_per=5000)\n",
    "\n",
    "modelo_skipgram.train(lista_de_lista_de_tokens, \n",
    "                     total_examples=modelo_skipgram.corpus_count,\n",
    "                     epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b884fa4e-81a8-440a-8395-93ddbc08a643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('medicine', 0.6029475927352905),\n",
       " ('published', 0.5571476817131042),\n",
       " ('editorial', 0.544950544834137),\n",
       " ('jacksons', 0.4870747923851013),\n",
       " ('alexanders', 0.4798334240913391),\n",
       " ('findings', 0.4683205783367157),\n",
       " ('keizai', 0.46573489904403687),\n",
       " ('article', 0.4626763164997101),\n",
       " ('newspaper', 0.45614340901374817),\n",
       " ('deny', 0.4538005292415619)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-5:\n",
      "Process Process-3:\n",
      "Process Process-7:\n",
      "Process Process-8:\n",
      "Process Process-6:\n",
      "Process Process-1:\n",
      "Process Process-4:\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/site-packages/spacy/language.py\", line 2219, in _apply_pipes\n",
      "    sender.send(byte_docs + padding)  # type: ignore[operator]\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 211, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 410, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/site-packages/spacy/language.py\", line 2219, in _apply_pipes\n",
      "    sender.send(byte_docs + padding)  # type: ignore[operator]\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 211, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 410, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/site-packages/spacy/language.py\", line 2219, in _apply_pipes\n",
      "    sender.send(byte_docs + padding)  # type: ignore[operator]\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 211, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 410, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/site-packages/spacy/language.py\", line 2219, in _apply_pipes\n",
      "    sender.send(byte_docs + padding)  # type: ignore[operator]\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 211, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 410, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/site-packages/spacy/language.py\", line 2219, in _apply_pipes\n",
      "    sender.send(byte_docs + padding)  # type: ignore[operator]\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 211, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 410, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/site-packages/spacy/language.py\", line 2219, in _apply_pipes\n",
      "    sender.send(byte_docs + padding)  # type: ignore[operator]\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 211, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 410, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/site-packages/spacy/language.py\", line 2219, in _apply_pipes\n",
      "    sender.send(byte_docs + padding)  # type: ignore[operator]\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 211, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 410, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/site-packages/spacy/language.py\", line 2219, in _apply_pipes\n",
      "    sender.send(byte_docs + padding)  # type: ignore[operator]\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 211, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 410, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/Users/fagnercandido/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "modelo_skipgram.wv.most_similar('journal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dabaa31-efc1-4267-a02f-aca77fee74e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
